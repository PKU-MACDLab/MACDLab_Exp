
1.linefollow with Radar obstacle avoidance (sensor: radar, camera)
roslaunch simple_follower line_follower.launch 

2.Follow through radar (sensor: radar)
roslaunch simple_follower laser_follower.launch 

3.Track the red block (sensor: camera)
roslaunch simple_follower visual_follower.launch 

4.3d_mapping 3d_navigation (sensor: radar, camera)
roslaunch turn_on_wheeltec_robot 3d_mapping.launch 
roslaunch turn_on_wheeltec_robot 3d_navigation.launch 

5.2d_mapping 2d_navigation (sensor: radar)
roslaunch turn_on_wheeltec_robot mapping.launch 
roslaunch turn_on_wheeltec_robot navigation.launch 
save map
roslaunch turn_on_wheeltec_robot map_saver.launch 

6.KCF track (sensor: camera)
roslaunch kcf_track kcf_tracker.launch

7.AR tag recognition (sensor: camera)
roslaunch turn_on_wheeltec_robot ar_label.launch
   
8.pure3d_mapping pure3d_navigation  (sensor: camera)
roslaunch turn_on_wheeltec_robot pure3d_mapping.launch
roslaunch turn_on_wheeltec_robot pure3d_navigation.launch

9.Voice control (Voice module required)
//Open the bottom, navigation, and radar scan nodes
roslaunch xf_mic_asr_offline base.launch
//Enable the microphone array initialization node
roslaunch xf_mic_asr_offline mic_init.launch
//Turn on voice control related nodes
roslaunch xf_mic_asr_offline voice_control.launch

10.The Web browser displays the camera (sensor: camera)
The host：roslaunch usb_cam usb_cam-test.launch
          rosrun web_video_server web_video_server
Host page view：http://localhost:8080/(The host issuing the hot spot is the host)
Client Web View：http://192.168.0.100:8080 (The client is connected to the hot spot)

11.Object recognition (no support for Raspberry Pi 4B 2GB)(sensor: camera)
Object recognition：roslaunch ros_detection ros_tensorflow_classify.launch
View the live camera footage：rqt_image_view (topic: /camera/rgb/image_raw/compressed)

12.For details, see the function tutorial of independent drawing (sensor: radar)
//Launch RRT_SLAM. Launch file:
roslaunch turn_on_wheeltec_robot rrt_slam.launch
//Open RVIZ, click "Add" → "By Topic" at the bottom left to add configuration plugins:
clicked_point	Show the range point and starting point of the random number
detected_points	Boundary point detected
frontiers		The boundary points received by the filter, the data are the same as above
centroids		The effective boundary point after filtering
global_detector_shapes	Global tree
local_detector_shapes	Local tree
// With the Publish Point tool of RVIZ, set four boundary points of the growth tree clockwise or counterclockwise, and a starting point of the growth tree (as close as possible to the starting point of the robot). After setting, the robot will explore the map based on the growth tree.

13.Flight of more(You need multiple cars)
// First, all cars must be on the same network (WiFi), and then modify the.bashrc file to set the master and slave. See the multi-machine formations tutorial
// After logging in remotely using the SSH command, click "Broadcast to All" in the upper left corner of the split terminal to synchronize the time using the command
sudo date -s "2021-01-30 08:48:00"
//The host starts the navigation node
roslaunch turn_on_wheeltec_robot navigation.launch 
//Start slave initialization node from slave 1
roslaunch wheeltec_multi wheeltec_slave.launch
//Slave 2 starts the slave initialization node (the two slaves need to use a high-performance router to provide WiFi)
roslaunch wheeltec_multi wheeltec_slave.launch
//The master opens the control slave node
roslaunch wheeltec_multi robot_tf.launch

14.Wheeltec App for Graphic Transfer, Mapping and Navigation
// The user's mobile phone is connected to the car WiFi, and then open the APP to use.The APP can control car movement, save maps and view camera images, as described in the Wheeltec APP functional tutorial
//Figure transmission, you need to manually open the RGB camera node:
roslaunch usb_cam usb_cam-test.launch (The APP side can view behind the camera in real time)
//To build a map, manually open the node of building a map:
roslaunch turn_on_wheeltec_robot mapping.launch 
APP terminal can view the drawing effect and save, and control the car movement at the same time
//To navigate, manually open the navigation node:
roslaunch turn_on_wheeltec_robot navigation.launch 
APP terminal can control the car movement

------------------------------------------
Other common commands

Recursive modification of current (terminal) folder file modification time:
find ./* -exec touch {} \;

Run in workspace, install ROS feature pack all depend on:
rosdep install --from-paths src --ignore-src -r -y

Specify feature pack compilation:
catkin_make -DCATKIN_WHITELIST_PACKAGES="package name"
Uncompile the specified feature pack:
catkin_make -DCATKIN_WHITELIST_PACKAGES=""

SSH login：
ssh -Y wheeltec@192.168.0.100

NFS mount:
sudo mount -t nfs 192.168.0.100:/home/wheeltec/wheeltec_robot /mnt
NFS unmount:
sudo umount -t nfs 192.168.0.100:/home/wheeltec/wheeltec_robot /mnt

Start the initialization node：
roslaunch turn_on_wheeltec_robot turn_on_wheeltec_robot.launch

Keyboard control：
roslaunch wheeltec_robot_rc keyboard_teleop.launch

Open the map path：
cd /home/wheeltec/wheeltec_robot/src/turn_on_wheeltec_robot/map
Save the map manually：
rosrun map_server map_saver -f 20200714

Turn on the RGB camera：
roslaunch usb_cam usb_cam-test.launch
rqt_image_view

Turn on both the depth camera and the RGB camera：
roslaunch astra_camera astra.launch 
rqt_image_view

View node and topic relationships：
rqt_graph

Generate TF tree PDF：
rosrun tf view_frames
Check the TF tree：
rosrun rqt_tf_tree rqt_tf_tree

VNC adjusts the resolution：
xrandr --fb 1024x768

rosrun tf view_frames
evince frame.pdf


